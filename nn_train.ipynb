{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Chess Position Evaluator\n","\n","Chess has been a classic benchmark for Artifical Intelligence, Machine Learning, and Data Mining since their inception. Due to the simple deterministic rules of chess coupled with the exponential possibilities and difficult to evaluate positions, it has gained the focus of many researchers in Computer Science. Today, there are several sophisticated chess AIs that compete on a level above even the strongest chess Grand Masters in the world. While chess engines like stockfish (which this dataset is based off of) and AlphaGo are too complex to try to compete with here, lets see if we can use the evaluations of Stockfish to build a comperable position evaluation function.\n","\n","For this project I will be using the pytorch library and building a Neural Network with it."]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2021-12-08T00:52:53.576532Z","iopub.status.busy":"2021-12-08T00:52:53.575368Z","iopub.status.idle":"2021-12-08T00:52:53.585145Z","shell.execute_reply":"2021-12-08T00:52:53.583715Z","shell.execute_reply.started":"2021-12-08T00:52:53.576497Z"},"trusted":true},"outputs":[],"source":["# pytorch libraries\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","# for visualizing the results\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# for reading input data\n","import pandas as pd\n","\n","# for parsing the FEN of chess positions\n","import re\n"]},{"cell_type":"markdown","metadata":{},"source":["To represent a chess position, it is common to use [Forsythâ€“Edwards Notation (FEN)](http://https://en.wikipedia.org/wiki/Forsyth%E2%80%93Edwards_Notation) which contains all the necessary information to reconstruct a chess game from the current position. To make this information usable for a neural network, we will use a bit (actually a byte) to represent if a specific piece (white rook, white knight, etc...) is on a specific square on the 8x8 chess board. Since there are 6 different pieces and two different players, that means there are 12 specific pieces that could potentially be on each square. \n","\n","However, we still need to keep track of information like whose turn it is, which castling options are still legal, if en passant is possible, how many half moves since a pawn move or piece capture, and how many turns the game has had. To do this we use an additional 8x8 board where the rook locations represent castling rights, the 3rd and 6th rank (row) keep track of possible en passant moves, the e1 and e8 sqaure represent whose on move, and the 4th and 5th rank represent the number of half moves and full moves as binary numbers (max possible being 255) respectively.\n","\n","Below is a function to do this conversion."]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2021-12-08T00:52:53.588174Z","iopub.status.busy":"2021-12-08T00:52:53.587584Z","iopub.status.idle":"2021-12-08T00:52:53.608625Z","shell.execute_reply":"2021-12-08T00:52:53.607618Z","shell.execute_reply.started":"2021-12-08T00:52:53.588129Z"},"trusted":true},"outputs":[],"source":["def fen_to_bit_vector(fen):\n","    # piece placement - lowercase for black pieces, uppercase for white pieces. numbers represent consequtive spaces. / represents a new row \n","    # active color - whose turn it is, either 'w' or 'b'\n","    # castling rights - which castling moves are still legal K or k for kingside and Q or q for queenside, '-' if no legal castling moves for either player\n","    # en passant - if the last move was a pawn moving up two squares, this is the space behind the square for the purposes of en passant\n","    # halfmove clock - number of moves without a pawn move or piece capture, after 50 of which the game is a draw\n","    # fullmove number - number of full turns starting at 1, increments after black's move\n","\n","    # Example FEN of starting position\n","    # rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\n","    \n","    parts = re.split(\" \", fen)\n","    piece_placement = re.split(\"/\", parts[0])\n","    active_color = parts[1]\n","    castling_rights = parts[2]\n","    en_passant = parts[3]\n","    halfmove_clock = int(parts[4])\n","    fullmove_clock = int(parts[5])\n","\n","    bit_vector = np.zeros((13, 8, 8), dtype=np.uint8)\n","    \n","    # piece to layer structure taken from reference [1]\n","    piece_to_layer = {\n","        'R': 1,\n","        'N': 2,\n","        'B': 3,\n","        'Q': 4,\n","        'K': 5,\n","        'P': 6,\n","        'p': 7,\n","        'k': 8,\n","        'q': 9,\n","        'b': 10,\n","        'n': 11,\n","        'r': 12\n","    }\n","    \n","    castling = {\n","        'K': (7,7),\n","        'Q': (7,0),\n","        'k': (0,7),\n","        'q': (0,0),\n","    }\n","\n","    for r, row in enumerate(piece_placement):\n","        c = 0\n","        for piece in row:\n","            if piece in piece_to_layer:\n","                bit_vector[piece_to_layer[piece], r, c] = 1\n","                c += 1\n","            else:\n","                c += int(piece)\n","    \n","    if en_passant != '-':\n","        bit_vector[0, ord(en_passant[0]) - ord('a'), int(en_passant[1]) - 1] = 1\n","    \n","    if castling_rights != '-':\n","        for char in castling_rights:\n","            bit_vector[0, castling[char][0], castling[char][1]] = 1\n","    \n","    if active_color == 'w':\n","        bit_vector[0, 7, 4] = 1\n","    else:\n","        bit_vector[0, 0, 4] = 1\n","\n","    if halfmove_clock > 0:\n","        c = 7\n","        while halfmove_clock > 0:\n","            bit_vector[0, 3, c] = halfmove_clock%2\n","            halfmove_clock = halfmove_clock // 2\n","            c -= 1\n","            if c < 0:\n","                break\n","\n","    if fullmove_clock > 0:\n","        c = 7\n","        while fullmove_clock > 0:\n","            bit_vector[0, 4, c] = fullmove_clock%2\n","            fullmove_clock = fullmove_clock // 2\n","            c -= 1\n","            if c < 0:\n","                break\n","\n","    return bit_vector\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2021-12-08T00:52:53.613106Z","iopub.status.busy":"2021-12-08T00:52:53.612383Z","iopub.status.idle":"2021-12-08T00:52:53.631679Z","shell.execute_reply":"2021-12-08T00:52:53.630012Z","shell.execute_reply.started":"2021-12-08T00:52:53.613073Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[[[1 0 0 0 0 0 0 1]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 1]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [1 0 0 0 1 0 0 1]]\n","\n"," [[0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [1 0 0 0 0 0 0 1]]\n","\n"," [[0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 1 0 0 0 0 1 0]]\n","\n"," [[0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 1 0 0 1 0 0]]\n","\n"," [[0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 1 0 0 0 0]]\n","\n"," [[0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 1 0 0 0]]\n","\n"," [[0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [1 1 1 1 1 1 1 1]\n","  [0 0 0 0 0 0 0 0]]\n","\n"," [[0 0 0 0 0 0 0 0]\n","  [1 1 1 1 1 1 1 1]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]]\n","\n"," [[0 0 0 0 1 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]]\n","\n"," [[0 0 0 1 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]]\n","\n"," [[0 0 1 0 0 1 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]]\n","\n"," [[0 1 0 0 0 0 1 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]]\n","\n"," [[1 0 0 0 0 0 0 1]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]\n","  [0 0 0 0 0 0 0 0]]]\n"]}],"source":["fen = \"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\"\n","board = fen_to_bit_vector(fen)\n","print(board)\n"]},{"cell_type":"markdown","metadata":{},"source":["The first 8x8 board (0th index) contains all the extra information and the following 12 boards (1 to 12) represent the locations of the pieces in the order \n","\n","1. White Rook\n","2. White Knight\n","3. White Bishop\n","4. White Queen\n","5. White King\n","6. White Pawn\n","7. Black Pawn\n","8. Black King\n","9. Black Queen\n","10. Black Bishop\n","11. Black Knight\n","12. Black Rook\n","\n","Notice how the pieces line up correctly with the starting position with the first board correctly indicating it is white to move."]},{"cell_type":"markdown","metadata":{},"source":["# Neural Network\n","\n","We'll begin with a simple Feed-Forward Neural Network that's fully connected. Neural Networks are named for their structure being analogous to neurons in the human brain. The idea is that, in the human brain, when a neuron gets an electrical impulse through its synapses it will sometimes fire an electrical impulse to other neurons, creating a chain reaction. For neural networks, our neurons are nodes our synapses are edges (with corresponding weights) and the firing of the neuron is the activation function and output of the node. \n","\n","![Perceptron](http://starship-knowledge.com/wp-content/uploads/2020/10/Perceptrons-1024x724.jpeg)\n","\n","The goal of the Neural Network is to have weights such that after all the chain reactions of nodes taking in inputs and producing outputs, the information output of the final node represents the evaluation of the chess position that began the process. In order to actually find such weights we will use a method known as backpropagation, which iteratively adjusts the weights in the network to nudge the output closer to the answer we desire.\n","\n","Technically speaking, for each training record (a FEN and an evaulation) we input the position into the Neural Network, and after we get a result we compute the error between the result and the correct evaluation which can be represented as a error function. To change the weights in such a way as to minimize this error function we compute the gradient of the error function and adjust the weights in the opposite direction. This means that if we overshoot we want to decrease our evaluation and if we undershoot we want to increase our evaluation.\n","\n","![Gradient Descent](https://sebastianraschka.com/images/blog/2015/singlelayer_neural_networks_files/perceptron_gradient_descent_1.png)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2021-12-08T00:52:53.635606Z","iopub.status.busy":"2021-12-08T00:52:53.634710Z","iopub.status.idle":"2021-12-08T00:52:53.645069Z","shell.execute_reply":"2021-12-08T00:52:53.643677Z","shell.execute_reply.started":"2021-12-08T00:52:53.635533Z"},"trusted":true},"outputs":[],"source":["class Net(nn.Module):\n","\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.fc1 = nn.Linear(832, 832)\n","        self.fc2 = nn.Linear(832, 416)\n","        self.fc3 = nn.Linear(416, 208)\n","        self.fc4 = nn.Linear(208, 104)\n","        self.fc5 = nn.Linear(104, 1)\n","        self.dropout = nn.Dropout(0.2)\n","        self.lrelu = nn.LeakyReLU()\n","\n","\n","    def forward(self, x):\n","        x = torch.flatten(x, 1)\n","        x = self.fc1(x)\n","        x = self.dropout(x)\n","        x = self.lrelu(x)\n","        \n","        x = self.fc2(x)\n","        x = self.dropout(x)\n","        x = self.lrelu(x)\n","        \n","        x = self.fc3(x)\n","        x = self.dropout(x)\n","        x = self.lrelu(x)\n","        \n","        x = self.fc4(x)\n","        x = self.dropout(x)\n","        x = self.lrelu(x)\n","\n","        x = self.fc5(x)\n","        return x\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["class ConvNet(nn.Module):\n","    def __init__(self):\n","        super(ConvNet, self).__init__()\n","        self.lrelu = nn.LeakyReLU(0.01)\n","\n","\n","    def forward(self, x):\n","        x = torch.flatten(x, 1)\n","        \n","        return x\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2021-12-08T00:52:53.649048Z","iopub.status.busy":"2021-12-08T00:52:53.648523Z","iopub.status.idle":"2021-12-08T00:52:53.661072Z","shell.execute_reply":"2021-12-08T00:52:53.659645Z","shell.execute_reply.started":"2021-12-08T00:52:53.648985Z"},"trusted":true},"outputs":[],"source":["# ChessDataset code and eval_to_int code taken from reference [1]\n","class ChessDataset(Dataset):\n","    def __init__(self, data_frame):\n","        self.fens = torch.from_numpy(np.array([*map(fen_to_bit_vector, data_frame[\"FEN\"])], dtype=np.float32))\n","        self.evals = torch.Tensor([[x] for x in data_frame[\"Evaluation\"]])\n","        self._len = len(self.evals)\n","        \n","    def __len__(self):\n","        return self._len\n","    \n","    def __getitem__(self, index):\n","        return self.fens[index], self.evals[index]\n","\n","\n","def eval_to_int(evaluation):\n","    try:\n","        res = int(evaluation)\n","    except ValueError:\n","        res = 10000 if evaluation[1] == '+' else -10000\n","    return res / 100\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2021-12-08T00:52:53.672627Z","iopub.status.busy":"2021-12-08T00:52:53.672372Z","iopub.status.idle":"2021-12-08T00:52:53.689993Z","shell.execute_reply":"2021-12-08T00:52:53.688427Z","shell.execute_reply.started":"2021-12-08T00:52:53.672590Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device cuda\n"]}],"source":["epochs = 20\n","batch_size = 100\n","MAX_DATA = 500000\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device {}\".format(device))\n","\n","def AdamW_main():\n","    print(\"Preparing Training Data...\")\n","    train_data = pd.read_csv(\"chessData.csv\")\n","    train_data = train_data[:MAX_DATA]\n","    train_data[\"Evaluation\"] = train_data[\"Evaluation\"].map(eval_to_int)\n","    trainset = ChessDataset(train_data)\n","    \n","    print(\"Preparing Test Data...\")\n","    test_data = pd.read_csv(\"tactic_evals.csv\")\n","    test_data = test_data[:MAX_DATA]\n","    test_data[\"Evaluation\"] = test_data[\"Evaluation\"].map(eval_to_int)\n","    testset = ChessDataset(test_data)\n","\n","    print(\"Converting to pytorch Dataset...\")\n","\n","    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n","\n","    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n","\n","\n","    net = Net().to(device)\n","    criterion = nn.MSELoss()\n","    optimizer = optim.AdamW(net.parameters())\n","\n","\n","    for epoch in range(epochs):  # loop over the dataset multiple times\n","\n","        running_loss = 0.0\n","        for i, data in enumerate(trainloader, 0):\n","            inputs, labels = data\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            optimizer.zero_grad()\n","\n","            outputs = net(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            # print statistics\n","            running_loss += loss.item()\n","            if i % 500 == 499:    # print every 2000 mini-batches\n","                # denominator for loss should represent the number of positions evaluated \n","                # independent of the batch size\n","                print('[%d, %d] loss: %.3f' % (epoch + 1, i + 1, running_loss / (500*len(labels))))\n","                running_loss = 0.0\n","\n","    print('Finished Training')\n","\n","    PATH = './chess_fc_dropout_1mil.pth'\n","    torch.save(net.state_dict(), PATH)\n","\n","    print('Evaluating model')\n","\n","    count = 0\n","    total_loss = 0\n","    # since we're not training, we don't need to calculate the gradients for our outputs\n","    with torch.no_grad():\n","        for data in testloader:\n","            inputs, labels = data\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            outputs = net(inputs)\n","            loss = criterion(outputs, labels)\n","            \n","            # count should represent the number of positions evaluated \n","            # independent of the batch size\n","            count += len(labels)\n","            total_loss += loss\n","            if count % 10000 == 0:\n","                print('Average error of the model on the {} tactics positions is {}'.format(count, loss/count))\n","    #print('Average error of the model on the {} tactics positions is {}'.format(count, loss/count))\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2021-12-08T00:52:53.693276Z","iopub.status.busy":"2021-12-08T00:52:53.692718Z","iopub.status.idle":"2021-12-08T01:03:45.822536Z","shell.execute_reply":"2021-12-08T01:03:45.820262Z","shell.execute_reply.started":"2021-12-08T00:52:53.693230Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Preparing Training Data...\n","Preparing Test Data...\n","Converting to pytorch Dataset...\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9948\\1196567392.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mAdamW_main\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9948\\3627564290.py\u001b[0m in \u001b[0;36mAdamW_main\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m             \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'numpy'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'string_'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["AdamW_main()"]},{"cell_type":"markdown","metadata":{},"source":["# Results\n","\n","An average error of 0.0225 seems very reasonable, however this is not as amazing as it might at first seem since positions where stockfish's evaluation is not forced mate have been normalized to a range from approximately -1.5 to 1.5 and positions where stockfish's evalutaion is forced mate have been set to -100 or 100. By convention a positive score indicates an advantage for white and a negative score indicates an advantage for black."]},{"cell_type":"markdown","metadata":{},"source":["# Testing Optimization Algorithms\n","\n","Originally we used the AdamW algorithm for the optimization step, but what if we try Stochastic Gradient Descent (SGD)?"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-08T01:03:45.827234Z","iopub.status.busy":"2021-12-08T01:03:45.826610Z","iopub.status.idle":"2021-12-08T01:03:45.845288Z","shell.execute_reply":"2021-12-08T01:03:45.843753Z","shell.execute_reply.started":"2021-12-08T01:03:45.827180Z"},"trusted":true},"outputs":[],"source":["def SGD_main():\n","    MAX_DATA = 100000\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    print(\"Using device {}\".format(device))\n","\n","    print(\"Preparing Training Data...\")\n","    train_data = pd.read_csv(\"/kaggle/input/chess-evaluations/chessData.csv\")\n","    train_data = train_data[:MAX_DATA]\n","    train_data[\"Evaluation\"] = train_data[\"Evaluation\"].map(eval_to_int)\n","    trainset = ChessDataset(train_data)\n","    \n","    print(\"Preparing Test Data...\")\n","    test_data = pd.read_csv(\"/kaggle/input/chess-evaluations/tactic_evals.csv\")\n","    test_data = test_data[:MAX_DATA]\n","    test_data[\"Evaluation\"] = test_data[\"Evaluation\"].map(eval_to_int)\n","    testset = ChessDataset(test_data)\n","\n","    batch_size = 10\n","\n","    print(\"Converting to pytorch Dataset...\")\n","\n","    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n","\n","    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n","\n","\n","    net = Net().to(device)\n","    criterion = nn.MSELoss()\n","    optimizer = optim.SGD(net.parameters(), lr = 0.01)\n","\n","\n","    for epoch in range(10):  # loop over the dataset multiple times\n","\n","        running_loss = 0.0\n","        for i, data in enumerate(trainloader, 0):\n","            inputs, labels = data\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            optimizer.zero_grad()\n","\n","            outputs = net(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            # print statistics\n","            running_loss += loss.item()\n","            if i % 2000 == 1999:    # print every 2000 mini-batches\n","                # denominator for loss should represent the number of positions evaluated \n","                # independent of the batch size\n","                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / (2000*len(labels))))\n","                running_loss = 0.0\n","\n","    print('Finished Training')\n","\n","    PATH = './chess.pth'\n","    torch.save(net.state_dict(), PATH)\n","\n","    print('Evaluating model')\n","\n","    count = 0\n","    total_loss = 0\n","    # since we're not training, we don't need to calculate the gradients for our outputs\n","    with torch.no_grad():\n","        for data in testloader:\n","            inputs, labels = data\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            outputs = net(inputs)\n","            loss = criterion(outputs, labels)\n","            #print(\"Correct eval: {}, Predicted eval: {}, loss: {}\".format(labels, outputs, loss))\n","            \n","            # count should represent the number of positions evaluated \n","            # independent of the batch size\n","            count += len(labels)\n","            total_loss += loss\n","            if count % 10000 == 0:\n","                print('Average error of the model on the {} tactics positions is {}'.format(count, loss/count))\n","    #print('Average error of the model on the {} tactics positions is {}'.format(count, loss/count))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-08T01:08:45.685477Z","iopub.status.busy":"2021-12-08T01:08:45.685150Z","iopub.status.idle":"2021-12-08T01:17:20.817600Z","shell.execute_reply":"2021-12-08T01:17:20.816351Z","shell.execute_reply.started":"2021-12-08T01:08:45.685445Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device cuda\n","Preparing Training Data...\n"]},{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/chess-evaluations/chessData.csv'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17424\\538297080.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mSGD_main\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17424\\225776546.py\u001b[0m in \u001b[0;36mSGD_main\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Preparing Training Data...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/kaggle/input/chess-evaluations/chessData.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mMAX_DATA\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Evaluation\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Evaluation\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_to_int\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"encoding_errors\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"strict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m         )\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m             )\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/chess-evaluations/chessData.csv'"]}],"source":["SGD_main()"]},{"cell_type":"markdown","metadata":{},"source":["An average error of 0.0207 is a slight improvement, but not so much that we can definitively say that SGD did better than AdamW. Since the training loss did not decrease by much throughout the 10 epochs, it's much more likely that either SGD is a worse optimizer for this classification problem or the learning rate is too large which is preventing the model from converging to the local optimum. Let's try again but with a learning rate of 0.001"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-08T01:22:35.869908Z","iopub.status.busy":"2021-12-08T01:22:35.869055Z","iopub.status.idle":"2021-12-08T01:22:35.887094Z","shell.execute_reply":"2021-12-08T01:22:35.885854Z","shell.execute_reply.started":"2021-12-08T01:22:35.869872Z"},"trusted":true},"outputs":[],"source":["def SGD_lr_main(learning_rate):\n","    MAX_DATA = 100000\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    print(\"Using device {}\".format(device))\n","\n","    print(\"Preparing Training Data...\")\n","    train_data = pd.read_csv(\"/kaggle/input/chess-evaluations/chessData.csv\")\n","    train_data = train_data[:MAX_DATA]\n","    train_data[\"Evaluation\"] = train_data[\"Evaluation\"].map(eval_to_int)\n","    trainset = ChessDataset(train_data)\n","    \n","    print(\"Preparing Test Data...\")\n","    test_data = pd.read_csv(\"/kaggle/input/chess-evaluations/tactic_evals.csv\")\n","    test_data = test_data[:MAX_DATA]\n","    test_data[\"Evaluation\"] = test_data[\"Evaluation\"].map(eval_to_int)\n","    testset = ChessDataset(test_data)\n","\n","    batch_size = 10\n","\n","    print(\"Converting to pytorch Dataset...\")\n","\n","    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n","\n","    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n","\n","\n","    net = Net().to(device)\n","    criterion = nn.MSELoss()\n","    optimizer = optim.SGD(net.parameters(), lr = learning_rate)\n","\n","\n","    for epoch in range(10):  # loop over the dataset multiple times\n","\n","        running_loss = 0.0\n","        for i, data in enumerate(trainloader, 0):\n","            inputs, labels = data\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            optimizer.zero_grad()\n","\n","            outputs = net(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            # print statistics\n","            running_loss += loss.item()\n","            if i % 2000 == 1999:    # print every 2000 mini-batches\n","                # denominator for loss should represent the number of positions evaluated \n","                # independent of the batch size\n","                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / (2000*len(labels))))\n","                running_loss = 0.0\n","\n","    print('Finished Training')\n","\n","    PATH = './chess.pth'\n","    torch.save(net.state_dict(), PATH)\n","\n","    print('Evaluating model')\n","\n","    count = 0\n","    total_loss = 0\n","    # since we're not training, we don't need to calculate the gradients for our outputs\n","    with torch.no_grad():\n","        for data in testloader:\n","            inputs, labels = data\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            outputs = net(inputs)\n","            loss = criterion(outputs, labels)\n","            #print(\"Correct eval: {}, Predicted eval: {}, loss: {}\".format(labels, outputs, loss))\n","            \n","            # count should represent the number of positions evaluated \n","            # independent of the batch size\n","            count += len(labels)\n","            total_loss += loss\n","            if count % 10000 == 0:\n","                print('Average error of the model on the {} tactics positions is {}'.format(count, loss/count))\n","    #print('Average error of the model on the {} tactics positions is {}'.format(count, loss/count))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-08T01:22:50.606020Z","iopub.status.busy":"2021-12-08T01:22:50.605655Z","iopub.status.idle":"2021-12-08T01:31:28.722260Z","shell.execute_reply":"2021-12-08T01:31:28.721102Z","shell.execute_reply.started":"2021-12-08T01:22:50.605977Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device cuda\n","Preparing Training Data...\n","Preparing Test Data...\n","Converting to pytorch Dataset...\n","[1,  2000] loss: 8.440\n","[1,  4000] loss: 9.587\n","[1,  6000] loss: 9.200\n","[1,  8000] loss: 9.099\n","[1, 10000] loss: 10.472\n","[2,  2000] loss: 9.207\n","[2,  4000] loss: 9.295\n","[2,  6000] loss: 8.579\n","[2,  8000] loss: 8.531\n","[2, 10000] loss: 8.224\n","[3,  2000] loss: 8.834\n","[3,  4000] loss: 6.915\n","[3,  6000] loss: 7.801\n","[3,  8000] loss: 9.602\n","[3, 10000] loss: 8.839\n","[4,  2000] loss: 8.003\n","[4,  4000] loss: 7.340\n","[4,  6000] loss: 7.545\n","[4,  8000] loss: 7.403\n","[4, 10000] loss: 8.222\n","[5,  2000] loss: 7.645\n","[5,  4000] loss: 8.381\n","[5,  6000] loss: 7.654\n","[5,  8000] loss: 6.861\n","[5, 10000] loss: 8.815\n","[6,  2000] loss: 7.837\n","[6,  4000] loss: 6.889\n","[6,  6000] loss: 7.066\n","[6,  8000] loss: 7.349\n","[6, 10000] loss: 7.577\n","[7,  2000] loss: 6.622\n","[7,  4000] loss: 7.293\n","[7,  6000] loss: 6.500\n","[7,  8000] loss: 6.772\n","[7, 10000] loss: 7.374\n","[8,  2000] loss: 6.713\n","[8,  4000] loss: 6.339\n","[8,  6000] loss: 6.384\n","[8,  8000] loss: 5.813\n","[8, 10000] loss: 6.157\n","[9,  2000] loss: 5.588\n","[9,  4000] loss: 7.334\n","[9,  6000] loss: 5.551\n","[9,  8000] loss: 7.556\n","[9, 10000] loss: 5.963\n","[10,  2000] loss: 7.249\n","[10,  4000] loss: 6.662\n","[10,  6000] loss: 6.597\n","[10,  8000] loss: 6.537\n","[10, 10000] loss: 6.480\n","Finished Training\n","Evaluating model\n","Average error of the model on the 10000 tactics positions is 0.10545970499515533\n","Average error of the model on the 20000 tactics positions is 0.0016649594763293862\n","Average error of the model on the 30000 tactics positions is 0.0006833095685578883\n","Average error of the model on the 40000 tactics positions is 0.00040360583807341754\n","Average error of the model on the 50000 tactics positions is 0.0007089063874445856\n","Average error of the model on the 60000 tactics positions is 0.0007821189356036484\n","Average error of the model on the 70000 tactics positions is 0.0608370341360569\n","Average error of the model on the 80000 tactics positions is 0.02596285007894039\n","Average error of the model on the 90000 tactics positions is 0.023554453626275063\n","Average error of the model on the 100000 tactics positions is 0.0213568527251482\n"]}],"source":["SGD_lr_main(0.001)"]},{"cell_type":"markdown","metadata":{},"source":["The training error seems like it's decreasing even if sporadic, but the classification error got slightly worse. It seems like AdamW is simply more consistant and converges faster to a local optimum."]},{"cell_type":"markdown","metadata":{},"source":["# Conclusion\n","\n","AdamW seems to be a more consistant algorithm and one which converges more quickly to a local optimum based on the comparision of AdamW, SGD(lr=0.01), and SGD(lr=0.001)\n","\n","This means the best model had an average error of 0.0225 as opposed to the lowest average error of 0.0207 which is not significant enough of a difference to justify the inconsistancy of the SGD optimizer."]},{"cell_type":"markdown","metadata":{},"source":["# Challenges\n","\n","This dataset (or at least the chessData.csv dataset) has over 16 million positions and evaluations which makes it rather difficult to work with. Because of this I've had to limit the amount of data actually used to 200,000 positions, 100,000 in the training dataset and 100,000 in the test dataset. "]},{"cell_type":"markdown","metadata":{},"source":["# References\n","\n","1. https://www.kaggle.com/ronakbadhe/chess-evaluation-prediction\n","2. https://en.wikipedia.org/wiki/Forsyth%E2%80%93Edwards_Notation\n","3. http://starship-knowledge.com/wp-content/uploads/2020/10/Perceptrons-1024x724.jpeg\n","4. https://starship-knowledge.com/wp-content/uploads/2020/10/Perceptrons-1024x724.jpeg"]},{"cell_type":"markdown","metadata":{},"source":["# Contribution\n","\n","* Representation of castling rights, en passant, active color, halfmoves and fullmoves in an 8x8 grid\n","* Neural Network Architecture\n","* Testing AdamW vs SVG"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"}},"nbformat":4,"nbformat_minor":4}
